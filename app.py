# -*- coding: utf-8 -*-
# Streamlit Appï¼šGoodinfo å¹´å¢žçŽ‡ + è²¡å‹™æ¯”çŽ‡ + é›·é”åœ–ï¼ˆRender / Google Drive ç‰ˆï¼‰
# ---------------------------------------------------------------
# ç‰¹è‰²ï¼š
# - ä»¥ Google Drive ä¸‹è¼‰é€£çµè®€å–å››å€‹ CSVï¼ˆç©©å®šã€å¯å…¬é–‹å­˜å–ï¼‰
# - è‡ªå‹•åµæ¸¬ç·¨ç¢¼ (utf-8-sig / utf-8 / big5)
# - ä¿ç•™åŽŸæœ¬å„€è¡¨æ¿æ‰€æœ‰è¦–è¦ºåŒ–åŠŸèƒ½ï¼ˆK ç·šã€å¹´å¢žçŽ‡ã€è²¡å‹™æ¯”çŽ‡ã€é›·é”åœ–ã€æŽ’è¡Œã€é€£çºŒæˆé•·ï¼‰
# - æ–°å¢žã€ŒæŠ˜ç·šåœ–æ¨£å¼ã€åˆ‡æ›ï¼ˆmarkers only æˆ– lines+markersï¼‰
# - å·²ç§»é™¤æ‰€æœ‰ Selenium èˆ‡ã€Œè³‡æ–™æ›´æ–°æŽ§åˆ¶å€ã€
# ---------------------------------------------------------------

import os, re, time, copy, io, requests
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from plotly.subplots import make_subplots
from requests.exceptions import HTTPError, RequestException

# =========================
# 0) å…¨åŸŸè¨­å®š
# =========================
st.set_page_config(page_title="å¹´å¢žçŽ‡ + è²¡å‹™æ¯”çŽ‡åˆ†æžå„€è¡¨æ¿ (Render/Drive)", layout="wide")

# === ä½ çš„ Google Drive æª”æ¡ˆ IDï¼ˆä»»ä½•çŸ¥é“é€£çµè€…å¯æª¢è¦–ï¼‰===
# è‹¥ä¹‹å¾Œæ›´æ–°ï¼Œåªéœ€æ›¿æ›é€™å››å€‹ ID æˆ–åœ¨å´é‚Šæ¬„è²¼å…¥æ–°çš„åˆ†äº«é€£çµå³å¯
GD_ID_YOY = "1sds9YcZi55eG3moooeueVHMsDVBx7JwB"
GD_ID_GM  = "1s8A_tFh4e8a1VxtYPJg0kocxoRjXlBIm"
GD_ID_OM  = "18r5PwDngcyzGf1wfGHWbOLmLeKqMdEyg"
GD_ID_CF  = "1gVgb0FpgRHPK1RW9_ym4HqsQeYZCUm1f"

# =========================
# 1) ä¸‹è¼‰/è®€æª”å·¥å…·
# =========================
def gdrive_id_from_any(url_or_id: str) -> str:
    """æŽ¥å— Google Drive åˆ†äº«é€£çµæˆ–ç´” IDï¼Œå›žå‚³ IDã€‚"""
    if "/file/d/" in url_or_id:
        m = re.search(r"/file/d/([^/]+)/", url_or_id)
        if m:
            return m.group(1)
    return url_or_id.strip()

def gdrive_csv_url(file_id: str) -> str:
    return f"https://drive.google.com/uc?export=download&id={file_id}"

@st.cache_data(show_spinner="Downloading CSV from Google Driveâ€¦", ttl=3600)
def read_csv_from_gdrive(file_id: str, timeout=15, max_retries=3) -> pd.DataFrame:
    """
    å¾ž Google Drive ä¸‹è¼‰ CSVï¼Œå˜—è©¦å¤šç¨®ç·¨ç¢¼ã€‚
    æœƒå¿«å– 1 å°æ™‚ä»¥æ¸›å°‘å¤–éƒ¨è«‹æ±‚ã€‚
    """
    url = gdrive_csv_url(file_id)
    last_err = None
    for attempt in range(1, max_retries + 1):
        try:
            r = requests.get(url, timeout=timeout)
            r.raise_for_status()
            raw = r.content
            # å˜—è©¦å¤šç¨®å¸¸è¦‹ç·¨ç¢¼
            for enc in ("utf-8-sig", "utf-8", "big5", "cp950"):
                try:
                    df = pd.read_csv(io.BytesIO(raw), encoding=enc)
                    return df
                except Exception:
                    continue
            # å¦‚æžœéƒ½ä¸è¡Œï¼Œå†ç”¨ pandas è‡ªå‹•æŽ¨æ¸¬ï¼ˆç„¡ encodingï¼‰
            try:
                df = pd.read_csv(io.BytesIO(raw))
                return df
            except Exception as e:
                last_err = e
        except RequestException as e:
            last_err = e
            time.sleep(1.2)  # ç°¡å–®é€€é¿
    raise RuntimeError(f"Failed to read CSV from Google Drive after {max_retries} tries: {last_err}")

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = df.columns.map(lambda x: str(x).replace("\xa0"," ").replace("\u3000"," ").strip())
    return df

# =========================
# 2) Yahoo Financeï¼šæ—¥ K ç·š
# =========================
@st.cache_data(show_spinner="Fetching price history from Yahooâ€¦", ttl=3600)
def fetch_history_from_2019(symbol: str) -> pd.DataFrame:
    start_dt = int(datetime(2019,1,1).timestamp())
    end_dt = int(time.time())
    headers = {"User-Agent":"Mozilla/5.0"}
    def fetch_with_suffix(suffix):
        url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}{suffix}"
        params = {"period1":start_dt,"period2":end_dt,"interval":"1d",
                  "includePrePost":"false","events":"div,splits"}
        resp = requests.get(url, params=params, headers=headers, timeout=20)
        resp.raise_for_status()
        return resp.json()
    try:
        data = fetch_with_suffix(".TW")
    except HTTPError:
        try:
            data = fetch_with_suffix(".TWO")
        except HTTPError:
            return pd.DataFrame()
    except Exception:
        return pd.DataFrame()

    try:
        result = data["chart"]["result"][0]
        ts = result["timestamp"]; q = result["indicators"]["quote"][0]
        adjclose = result["indicators"].get("adjclose",[{}])[0].get("adjclose",[None]*len(ts))
        df = pd.DataFrame({
            "Open": q["open"], "High": q["high"], "Low": q["low"],
            "Close": q["close"], "Volume": q["volume"], "AdjClose": adjclose
        }, index=pd.to_datetime(ts, unit="s"))
        df = df.dropna(subset=["Open","Close"])
        for w in (5,10,20,60,120,240):
            df[f"MA{w}"] = df["Close"].rolling(window=w).mean()
        return df
    except Exception:
        return pd.DataFrame()

# =========================
# 3) è³‡æ–™è¼‰å…¥ï¼ˆå¹´å¢žçŽ‡ + è²¡å‹™æ¯”çŽ‡ï¼‰
# =========================
@st.cache_data(show_spinner="Loading YOY dataâ€¦", ttl=3600)
def load_yoy_data_from_drive(file_id: str) -> pd.DataFrame:
    df = read_csv_from_gdrive(file_id)
    df = normalize_columns(df)

    # å›ºå®šè™•ç†ã€Œå¹³å‡ å¹´å¢žçŽ‡ã€
    if "å¹³å‡ å¹´å¢žçŽ‡" in df.columns and "å¹³å‡å¹´å¢žçŽ‡" not in df.columns:
        df["å¹³å‡å¹´å¢žçŽ‡"] = df["å¹³å‡ å¹´å¢žçŽ‡"]
        df.drop(columns=["å¹³å‡ å¹´å¢žçŽ‡"], inplace=True, errors="ignore")

    # å›ºå®šä½¿ç”¨ã€Œæ–°ç”¢æ¥­åˆ†é¡žã€æ¬„ä½ï¼Œæ”¹åç‚ºã€Œç”¢æ¥­åˆ†é¡žã€
    if "æ–°ç”¢æ¥­åˆ†é¡ž" in df.columns and "ç”¢æ¥­åˆ†é¡ž" not in df.columns:
        df.rename(columns={"æ–°ç”¢æ¥­åˆ†é¡ž": "ç”¢æ¥­åˆ†é¡ž"}, inplace=True)
    if "ç”¢æ¥­åˆ†é¡ž" not in df.columns:
        raise KeyError("âŒ æ‰¾ä¸åˆ°ã€Žæ–°ç”¢æ¥­åˆ†é¡žã€æˆ–ã€Žç”¢æ¥­åˆ†é¡žã€æ¬„ä½ï¼Œè«‹ç¢ºèª CSV æ ¼å¼ã€‚")

    # æŠ“å‡ºæ‰€æœ‰ã€Œå¹´å¢žçŽ‡ã€æ¬„ä½ï¼ˆæŽ’é™¤å¹³å‡ï¼‰
    yoy_cols = [c for c in df.columns if ("å¹´å¢žçŽ‡" in c) and (not str(c).strip().startswith("å¹³å‡"))]
    df[yoy_cols] = df[yoy_cols].apply(pd.to_numeric, errors="coerce")

    # å¯¬è½‰é•·
    df_m = df.melt(id_vars=["ä»£è™Ÿ","åç¨±","ç”¢æ¥­åˆ†é¡ž"], value_vars=yoy_cols,
                   var_name="æœŸé–“", value_name="å¹´å¢žçŽ‡")

    def parse_month_to_date(month_str):
        m = re.search(r"(\d{2})M(\d{2})", str(month_str))
        if m:
            y, mo = int(m.group(1)), int(m.group(2))
            return pd.Timestamp(year=2000 + y, month=mo, day=1)
        return pd.NaT
    df_m["æ—¥æœŸ"] = df_m["æœŸé–“"].apply(parse_month_to_date)
    return df_m

@st.cache_data(show_spinner="Loading financial ratiosâ€¦", ttl=3600)
def load_financial_ratios_from_drive(id_gm: str, id_om: str, id_cf: str) -> pd.DataFrame:
    gm = normalize_columns(read_csv_from_gdrive(id_gm))
    om = normalize_columns(read_csv_from_gdrive(id_om))
    cf = normalize_columns(read_csv_from_gdrive(id_cf))

    # æ¯›åˆ©çŽ‡
    gm_cols = [c for c in gm.columns if ("æ¯›åˆ©" in c and "%" in c) or re.search(r"\d{2}Q\d", str(c))]
    if "ä»£è™Ÿ" not in gm.columns or "åç¨±" not in gm.columns:
        # å˜—è©¦å¾žã€Œä»£è™Ÿåç¨±ã€åˆæ¬„æ‹†
        maybe = gm.columns[1] if len(gm.columns) > 1 else None
        if maybe:
            gm[["ä»£è™Ÿ","åç¨±"]] = gm[maybe].astype(str).str.extract(r"(\d{4})(.+)")
    gm_m = gm.melt(id_vars=[c for c in ["ä»£è™Ÿ","åç¨±"] if c in gm.columns],
                   value_vars=[c for c in gm_cols if c not in ["ä»£è™Ÿ","åç¨±"]],
                   var_name="æœŸé–“", value_name="æ¯›åˆ©çŽ‡")
    gm_m["å­£åº¦"] = gm_m["æœŸé–“"].astype(str).str.extract(r"(\d{2}Q\d)")[0]
    gm_m = gm_m.dropna(subset=["å­£åº¦"])
    gm_m["æ—¥æœŸ"] = pd.PeriodIndex(gm_m["å­£åº¦"], freq="Q").to_timestamp("Q")

    # ç‡Ÿç›ŠçŽ‡
    om_cols = [c for c in om.columns if ("ç‡Ÿç›Š" in c and "%" in c) or re.search(r"\d{2}Q\d", str(c))]
    if "ä»£è™Ÿ" not in om.columns or "åç¨±" not in om.columns:
        maybe = om.columns[1] if len(om.columns) > 1 else None
        if maybe:
            om[["ä»£è™Ÿ","åç¨±"]] = om[maybe].astype(str).str.extract(r"(\d{4})(.+)")
    om_m = om.melt(id_vars=[c for c in ["ä»£è™Ÿ","åç¨±"] if c in om.columns],
                   value_vars=[c for c in om_cols if c not in ["ä»£è™Ÿ","åç¨±"]],
                   var_name="æœŸé–“", value_name="ç‡Ÿç›ŠçŽ‡")
    om_m["å­£åº¦"] = om_m["æœŸé–“"].astype(str).str.extract(r"(\d{2}Q\d)")[0]
    om_m = om_m.dropna(subset=["å­£åº¦"])
    om_m["æ—¥æœŸ"] = pd.PeriodIndex(om_m["å­£åº¦"], freq="Q").to_timestamp("Q")

    # ç‡Ÿæ¥­é‡‘æµ
    cf_cols = [c for c in cf.columns if re.match(r"\d{2}Q\d.*ç‡Ÿæ¥­æ´»å‹•", str(c))]
    if "ä»£è™Ÿ" not in cf.columns or "åç¨±" not in cf.columns:
        maybe = cf.columns[1] if len(cf.columns) > 1 else None
        if maybe:
            cf[["ä»£è™Ÿ","åç¨±"]] = cf[maybe].astype(str).str.extract(r"(\d{4})(.+)")
    cf_m = cf.melt(id_vars=[c for c in ["ä»£è™Ÿ","åç¨±"] if c in cf.columns],
                   value_vars=[c for c in cf_cols if c not in ["ä»£è™Ÿ","åç¨±"]],
                   var_name="æœŸé–“", value_name="ç‡Ÿæ¥­é‡‘æµ")
    cf_m["å­£åº¦"] = cf_m["æœŸé–“"].astype(str).str.extract(r"(\d{2}Q\d)")[0]
    cf_m["æ—¥æœŸ"] = pd.PeriodIndex(cf_m["å­£åº¦"], freq="Q").to_timestamp("Q")
    cf_m = cf_m[["ä»£è™Ÿ","åç¨±","æ—¥æœŸ","ç‡Ÿæ¥­é‡‘æµ"]]

    # åˆä½µ
    df_fin = gm_m.merge(om_m[["ä»£è™Ÿ","åç¨±","æ—¥æœŸ","ç‡Ÿç›ŠçŽ‡"]], on=["ä»£è™Ÿ","åç¨±","æ—¥æœŸ"], how="outer")
    df_fin = df_fin.merge(cf_m, on=["ä»£è™Ÿ","åç¨±","æ—¥æœŸ"], how="outer")
    df_fin = df_fin.sort_values(["ä»£è™Ÿ","æ—¥æœŸ"]).reset_index(drop=True)
    # æ•¸å€¼è½‰åž‹
    for col in ["æ¯›åˆ©çŽ‡","ç‡Ÿç›ŠçŽ‡","ç‡Ÿæ¥­é‡‘æµ"]:
        if col in df_fin.columns:
            df_fin[col] = pd.to_numeric(df_fin[col], errors="coerce")
    return df_fin

# =========================
# 4) å´é‚Šæ¬„ï¼šè³‡æ–™ä¾†æº/é¸é …
# =========================
st.sidebar.title("ðŸ“‚ æŸ¥è©¢æ¢ä»¶ / æŽ§åˆ¶é¢æ¿")

with st.sidebar.expander("è³‡æ–™ä¾†æºï¼ˆå¯è²¼åˆ†äº«é€£çµè¦†è“‹ï¼‰", True):
    in_yoy = st.text_input("å¹´å¢žçŽ‡ï¼ˆDrive é€£çµæˆ– IDï¼‰", GD_ID_YOY)
    in_gm  = st.text_input("æ¯›åˆ©çŽ‡ï¼ˆDrive é€£çµæˆ– IDï¼‰", GD_ID_GM)
    in_om  = st.text_input("ç‡Ÿç›ŠçŽ‡ï¼ˆDrive é€£çµæˆ– IDï¼‰", GD_ID_OM)
    in_cf  = st.text_input("ç‡Ÿæ¥­é‡‘æµï¼ˆDrive é€£çµæˆ– IDï¼‰", GD_ID_CF)

    # æ­£è¦åŒ–æˆ ID
    id_yoy = gdrive_id_from_any(in_yoy)
    id_gm  = gdrive_id_from_any(in_gm)
    id_om  = gdrive_id_from_any(in_om)
    id_cf  = gdrive_id_from_any(in_cf)

# æŠ˜ç·šåœ–é¡¯ç¤ºæ¨£å¼é¸æ“‡
line_style = st.sidebar.radio("æŠ˜ç·šåœ–æ¨£å¼ï¼ˆè²¡å‹™æ¯”çŽ‡ï¼‰", ["ç·šæ¢ï¼‹åœ“é»ž", "åªæœ‰åœ“é»ž"], index=0)
markers_flag = True
mode_line = "lines+markers" if line_style == "ç·šæ¢ï¼‹åœ“é»ž" else "markers"

show_yoy = st.sidebar.checkbox("ðŸ“ˆ é¡¯ç¤ºæœˆç‡Ÿæ”¶å¹´å¢žçŽ‡ï¼ˆå«ç”¢æ¥­å¹³å‡ï¼‰", True)
show_kline = st.sidebar.checkbox("ðŸ•¯ï¸ é¡¯ç¤º K ç·š + å‡ç·šï¼ˆYahooï¼‰", True)
show_fin = st.sidebar.checkbox("ðŸ“Š é¡¯ç¤ºè²¡å‹™æ¯”çŽ‡ï¼ˆæ¯›åˆ©/ç‡Ÿç›Š/é‡‘æµï¼‰", True)
show_radar = st.sidebar.checkbox("ðŸ§­ å¹´åº¦é›·é”åœ–ï¼ˆæ¯›åˆ©/ç‡Ÿç›Š/é‡‘æµï¼‰", True)
show_radar_mix = st.sidebar.checkbox("ðŸ§­ ç¶œåˆé›·é”åœ–ï¼ˆæ¯›åˆ©/ç‡Ÿç›Š/é‡‘æµ/ç‡Ÿæ”¶å¹´å¢žçŽ‡ï¼‰", True)
normalize_radar = st.sidebar.checkbox("âš–ï¸ é›·é”åœ–æ­£è¦åŒ– (0-100)", True)

# =========================
# 5) è®€å–è³‡æ–™ï¼ˆDriveï¼‰
# =========================
with st.spinner("è®€å–è³‡æ–™ä¸­â€¦"):
    df_yoy = load_yoy_data_from_drive(id_yoy)
    df_fin = load_financial_ratios_from_drive(id_gm, id_om, id_cf)

# ç”¢æ¥­/è‚¡ç¥¨é¸å–®
inds = sorted(df_yoy['ç”¢æ¥­åˆ†é¡ž'].dropna().unique())
sel_inds = st.sidebar.multiselect("é¸æ“‡ç”¢æ¥­åˆ†é¡žï¼ˆå¯å¤šé¸ï¼‰", inds)
manual_input = st.sidebar.text_input("æˆ–è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿï¼ˆé€—è™Ÿåˆ†éš”ï¼‰", "2330,1101")
manual_codes = [c.strip() for c in manual_input.split(',') if c.strip()]

filtered = df_yoy.copy()
if sel_inds:
    filtered = filtered[filtered['ç”¢æ¥­åˆ†é¡ž'].isin(sel_inds)]
if manual_codes:
    filtered = pd.concat([filtered, df_yoy[df_yoy['ä»£è™Ÿ'].isin(manual_codes)]], ignore_index=True)

stocks = filtered[['ä»£è™Ÿ', 'åç¨±']].drop_duplicates()
opts = {f"{r['ä»£è™Ÿ']} {r['åç¨±']}": r['ä»£è™Ÿ'] for _, r in stocks.iterrows()}
default_keys = list(opts.keys())[:1] if len(opts) else []
selected = st.sidebar.multiselect("é¸æ“‡è‚¡ç¥¨", list(opts.keys()), default=default_keys)

st.markdown("## å¹´å¢žçŽ‡ + K ç·š + è²¡å‹™æ¯”çŽ‡ å„€è¡¨æ¿ï¼ˆDrive ç‰ˆï¼‰")

# =========================
# 6) å–®è‚¡åœ–è¡¨å€
# =========================
def normalize_values(values, all_data):
    if not normalize_radar: return values
    scaled = []
    for i, v in enumerate(values):
        col = all_data[i].dropna()
        if len(col) == 0:
            scaled.append(0); continue
        v = 0 if v is None or (isinstance(v, float) and np.isnan(v)) else v
        vmin, vmax = col.min(), col.max()
        if pd.isna(v) or pd.isna(vmin) or pd.isna(vmax):
            scaled.append(0); continue
        if vmax == vmin:
            scaled.append(50); continue
        scaled.append((v - vmin) / (vmax - vmin) * 100)
    return scaled

if len(selected) == 1:
    code = opts[selected[0]]

    # å¹´å¢žçŽ‡ï¼ˆè©²è‚¡ï¼‰
    yoy_s = df_yoy[df_yoy["ä»£è™Ÿ"] == code].sort_values("æ—¥æœŸ")

    # ç”¢æ¥­å¹³å‡
    if not yoy_s.empty:
        industry = yoy_s["ç”¢æ¥­åˆ†é¡ž"].iloc[0]
        ind_avg = df_yoy[df_yoy["ç”¢æ¥­åˆ†é¡ž"] == industry].groupby("æ—¥æœŸ")["å¹´å¢žçŽ‡"].mean().reset_index()
    else:
        industry, ind_avg = "æœªçŸ¥", pd.DataFrame(columns=["æ—¥æœŸ", "å¹´å¢žçŽ‡"])

    # --- K ç·š + å‡ç·š + æœˆç‡Ÿæ”¶å¹´å¢žçŽ‡ ---
    if show_kline:
        df_yf = fetch_history_from_2019(code)
        if df_yf.empty:
            st.warning(f"{code}.TW ç„¡æ³•å¾ž Yahoo Finance å–å¾—æ—¥ç·šè³‡æ–™")
        else:
            vol_colors = np.where(df_yf["Close"] >= df_yf["Open"], "red", "green")
            fig_k = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.05,
                                  row_heights=[0.8, 0.2], specs=[[{"secondary_y": True}], [{}]])
            fig_k.add_trace(
                go.Candlestick(x=df_yf.index, open=df_yf["Open"], high=df_yf["High"],
                               low=df_yf["Low"], close=df_yf["Close"], name="K ç·š",
                               increasing_line_color='red', decreasing_line_color='green'),
                row=1, col=1, secondary_y=False
            )
            for w in (5, 10, 20, 60, 120, 240):
                fig_k.add_trace(go.Scatter(x=df_yf.index, y=df_yf[f"MA{w}"], mode="lines", name=f"MA{w}"),
                                row=1, col=1, secondary_y=False)
            if not yoy_s.empty and show_yoy:
                fig_k.add_trace(go.Scatter(x=yoy_s["æ—¥æœŸ"], y=yoy_s["å¹´å¢žçŽ‡"], mode="lines+markers",
                                           name=f"{code} å¹´å¢žçŽ‡", line=dict(dash="dot")),
                                row=1, col=1, secondary_y=True)
            if not ind_avg.empty and show_yoy:
                fig_k.add_trace(go.Scatter(x=ind_avg["æ—¥æœŸ"], y=ind_avg["å¹´å¢žçŽ‡"], mode="lines+markers",
                                           name=f"{industry} å¹³å‡å¹´å¢žçŽ‡", line=dict(dash="dash")),
                                row=1, col=1, secondary_y=True)
            fig_k.add_trace(go.Bar(x=df_yf.index, y=df_yf["Volume"], marker_color=vol_colors,
                                   name="æˆäº¤é‡", showlegend=False), row=2, col=1)
            fig_k.update_layout(
                title=f"ðŸ•¯ï¸ {code}.TW K ç·š + å‡ç·š + æˆäº¤é‡ + æœˆç‡Ÿæ”¶å¹´å¢žçŽ‡ (å«ç”¢æ¥­å¹³å‡)",
                hovermode="x unified", height=760, dragmode="pan",
                xaxis=dict(rangeslider=dict(visible=True), type="date"),
                yaxis=dict(title="è‚¡åƒ¹"),
                yaxis2=dict(title="æœˆç‡Ÿæ”¶å¹´å¢žçŽ‡ (%)", overlaying="y", side="right", showgrid=False),
                yaxis3=dict(title="æˆäº¤é‡")
            )
            st.plotly_chart(fig_k, use_container_width=True,
                            config={"displaylogo": False, "modeBarButtonsToAdd": ["resetScale2d"]})

# =========================
# 7) è²¡å‹™æ¯”çŽ‡ + é›·é”åœ–
# =========================
if (show_fin or show_radar or show_radar_mix) and len(selected) == 1:
    code = opts[selected[0]]
    fin_s = df_fin[df_fin["ä»£è™Ÿ"] == code].sort_values("æ—¥æœŸ")
    yoy_s = df_yoy[df_yoy["ä»£è™Ÿ"] == code].sort_values("æ—¥æœŸ")

    if show_fin:
        st.markdown("### ðŸ“Š è²¡å‹™æ¯”çŽ‡è¶¨å‹¢")
        # æŠ˜ç·šåœ–ï¼šæ¯›åˆ©çŽ‡ / ç‡Ÿç›ŠçŽ‡
        ratio_cols = [c for c in ["æ¯›åˆ©çŽ‡", "ç‡Ÿç›ŠçŽ‡"] if c in fin_s.columns]
        if ratio_cols and not fin_s.empty:
            df_ratio = fin_s[["æ—¥æœŸ"] + ratio_cols].dropna(subset=["æ—¥æœŸ"])
            df_plot = df_ratio.melt(id_vars="æ—¥æœŸ", var_name="æŒ‡æ¨™", value_name="æ•¸å€¼")
            df_plot["æ•¸å€¼"] = pd.to_numeric(df_plot["æ•¸å€¼"], errors="coerce")
            df_plot = df_plot.sort_values("æ—¥æœŸ")

            fig = px.line(df_plot, x="æ—¥æœŸ", y="æ•¸å€¼", color="æŒ‡æ¨™", title=f"{code} æ¯›åˆ©çŽ‡ / ç‡Ÿç›ŠçŽ‡",
                          markers=(mode_line != "lines"))
            # ä½¿ç”¨è€…é¸é …ï¼šåªé¡¯ç¤ºåœ“é»ž or ç·š+é»ž
            fig.update_traces(mode=mode_line, connectgaps=True)

            fig.update_layout(template="plotly_dark", title_x=0.05,
                              hovermode="x unified", height=500, legend_title_text="æŒ‡æ¨™")
            st.plotly_chart(fig, use_container_width=True,
                            config={"displaylogo": False, "modeBarButtonsToAdd": ["resetScale2d"]})

        # ç¾é‡‘æµé‡æŸ±ç‹€åœ–
        if "ç‡Ÿæ¥­é‡‘æµ" in fin_s.columns and not fin_s["ç‡Ÿæ¥­é‡‘æµ"].dropna().empty:
            df_cf = fin_s[["æ—¥æœŸ", "ç‡Ÿæ¥­é‡‘æµ"]].dropna().sort_values("æ—¥æœŸ")
            fig_cf = px.bar(df_cf, x="æ—¥æœŸ", y="ç‡Ÿæ¥­é‡‘æµ", title=f"{code} ç‡Ÿæ¥­æ´»å‹•ç¾é‡‘æµé‡ï¼ˆå„„ï¼‰")
            fig_cf.update_layout(template="plotly_dark", hovermode="x unified", height=400)
            st.plotly_chart(fig_cf, use_container_width=True,
                            config={"displaylogo": False, "modeBarButtonsToAdd": ["resetScale2d"]})

    # å¹´ä»½æ¸…å–®ï¼ˆé›·é”åœ–ï¼‰
    years_fin = sorted(fin_s["æ—¥æœŸ"].dt.year.dropna().unique().tolist()) if not fin_s.empty else []
    years_yoy = sorted(yoy_s["æ—¥æœŸ"].dt.year.dropna().unique().tolist()) if not yoy_s.empty else []
    all_years = sorted(set(years_fin) | set(years_yoy))
    default_years = all_years[-1:] if all_years else []

    # å¹´åº¦é›·é”åœ–
    if show_radar:
        st.markdown("### ðŸ§­ å¹´åº¦é›·é”åœ–ï¼ˆæ¯›åˆ©çŽ‡ / ç‡Ÿç›ŠçŽ‡ / ç‡Ÿæ¥­é‡‘æµï¼‰")
        st.caption("ðŸ’¡ é›™æ“Šåœ–ä¸­å¿ƒå¯å›žå¾©åŽŸå§‹å¤§å°")
        chosen_years = st.multiselect("é¸æ“‡å¹´ä»½ï¼ˆè²¡å‹™æ¯”çŽ‡é›·é”åœ–ï¼‰", all_years, default=default_years, key="radar_fin_years")
        if chosen_years:
            categories = ["æ¯›åˆ©çŽ‡","ç‡Ÿç›ŠçŽ‡","ç‡Ÿæ¥­é‡‘æµ"]
            all_data = [fin_s["æ¯›åˆ©çŽ‡"], fin_s["ç‡Ÿç›ŠçŽ‡"], fin_s["ç‡Ÿæ¥­é‡‘æµ"]]
            fig_radar = go.Figure(); colors = px.colors.qualitative.Bold
            for i, yr in enumerate(chosen_years):
                color = colors[i % len(colors)]
                yr_df = fin_s[fin_s["æ—¥æœŸ"].dt.year == yr].sort_values("æ—¥æœŸ").tail(1)
                values = [
                    float(yr_df["æ¯›åˆ©çŽ‡"].values[0]) if not yr_df.empty and pd.notna(yr_df["æ¯›åˆ©çŽ‡"].values[0]) else 0,
                    float(yr_df["ç‡Ÿç›ŠçŽ‡"].values[0]) if not yr_df.empty and pd.notna(yr_df["ç‡Ÿç›ŠçŽ‡"].values[0]) else 0,
                    float(yr_df["ç‡Ÿæ¥­é‡‘æµ"].values[0]) if not yr_df.empty and pd.notna(yr_df["ç‡Ÿæ¥­é‡‘æµ"].values[0]) else 0,
                ]
                scaled = normalize_values(values, all_data)
                fig_radar.add_trace(go.Scatterpolar(
                    r=scaled, theta=categories, fill="toself", name=str(yr),
                    line=dict(color=color, width=2),
                    fillcolor=color.replace("rgb","rgba").replace(")",",0.3)"),
                    mode="lines+markers+text",
                    text=[f"{v:.1f}" for v in values], textfont=dict(color="black"),
                    textposition="top center"
                ))
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0,100] if normalize_radar else None)),
                title=f"{code} è²¡å‹™æ¯”çŽ‡é›·é”åœ–ï¼ˆå¹´åº¦æ¯”è¼ƒï¼‰", showlegend=True
            )
            st.plotly_chart(fig_radar, use_container_width=True, config={"displaylogo": False})

    # ç¶œåˆé›·é”åœ–
    if show_radar_mix:
        st.markdown("### ðŸ§­ ç¶œåˆé›·é”åœ–ï¼ˆæ¯›åˆ©çŽ‡ / ç‡Ÿç›ŠçŽ‡ / ç‡Ÿæ¥­é‡‘æµ / ç‡Ÿæ”¶å¹´å¢žçŽ‡ï¼‰")
        st.caption("ðŸ’¡ é›™æ“Šåœ–ä¸­å¿ƒå¯å›žå¾©åŽŸå§‹å¤§å°")
        chosen_years2 = st.multiselect("é¸æ“‡å¹´ä»½ï¼ˆç¶œåˆé›·é”åœ–ï¼‰", all_years, default=default_years, key="radar_mix_years")
        if chosen_years2:
            categories_all = ["æ¯›åˆ©çŽ‡","ç‡Ÿç›ŠçŽ‡","ç‡Ÿæ¥­é‡‘æµ","æœˆç‡Ÿæ”¶å¹´å¢žçŽ‡"]
            all_data = [fin_s["æ¯›åˆ©çŽ‡"], fin_s["ç‡Ÿç›ŠçŽ‡"], fin_s["ç‡Ÿæ¥­é‡‘æµ"], yoy_s["å¹´å¢žçŽ‡"]]
            fig_radar_all = go.Figure(); colors = px.colors.qualitative.Dark24
            for i, yr in enumerate(chosen_years2):
                color = colors[i % len(colors)]
                latest_fin = fin_s[fin_s["æ—¥æœŸ"].dt.year == yr].sort_values("æ—¥æœŸ").tail(1)
                latest_yoy = yoy_s[yoy_s["æ—¥æœŸ"].dt.year == yr].sort_values("æ—¥æœŸ").tail(1)
                values = [
                    float(latest_fin["æ¯›åˆ©çŽ‡"].values[0]) if not latest_fin.empty and pd.notna(latest_fin["æ¯›åˆ©çŽ‡"].values[0]) else 0,
                    float(latest_fin["ç‡Ÿç›ŠçŽ‡"].values[0]) if not latest_fin.empty and pd.notna(latest_fin["ç‡Ÿç›ŠçŽ‡"].values[0]) else 0,
                    float(latest_fin["ç‡Ÿæ¥­é‡‘æµ"].values[0]) if not latest_fin.empty and pd.notna(latest_fin["ç‡Ÿæ¥­é‡‘æµ"].values[0]) else 0,
                    float(latest_yoy["å¹´å¢žçŽ‡"].values[0]) if not latest_yoy.empty and pd.notna(latest_yoy["å¹´å¢žçŽ‡"].values[0]) else 0,
                ]
                scaled = normalize_values(values, all_data)
                fig_radar_all.add_trace(go.Scatterpolar(
                    r=scaled, theta=categories_all, fill="toself", name=str(yr),
                    line=dict(color=color, width=2),
                    fillcolor=color.replace("rgb","rgba").replace(")",",0.3)"),
                    mode="lines+markers+text",
                    text=[f"{v:.1f}" for v in values], textfont=dict(color="black"),
                    textposition="top center"
                ))
            fig_radar_all.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0,100] if normalize_radar else None)),
                title=f"{code} ç¶œåˆè²¡å‹™ + ç‡Ÿæ”¶é›·é”åœ–ï¼ˆå¹´åº¦æ¯”è¼ƒï¼‰", showlegend=True
            )
            st.plotly_chart(fig_radar_all, use_container_width=True, config={"displaylogo": False})

# =========================
# 8) å¹³å‡å¹´å¢žçŽ‡æŽ’è¡Œæ¦œ
# =========================
with st.expander("ðŸ† å¹³å‡å¹´å¢žçŽ‡æŽ’è¡Œæ¦œ Top 10", True):
    try:
        df_raw = normalize_columns(read_csv_from_gdrive(id_yoy))
        avg_col = next((c for c in df_raw.columns if c.strip() in ("å¹³å‡å¹´å¢žçŽ‡","å¹³å‡ å¹´å¢žçŽ‡")), None)
        if avg_col:
            df_avg = df_raw[["ä»£è™Ÿ","åç¨±", avg_col]].rename(columns={avg_col:"å¹³å‡å¹´å¢žçŽ‡"}).dropna()
            df_avg["å¹³å‡å¹´å¢žçŽ‡"] = pd.to_numeric(df_avg["å¹³å‡å¹´å¢žçŽ‡"], errors="coerce")
            rank_df = df_avg.sort_values("å¹³å‡å¹´å¢žçŽ‡", ascending=False).head(10).reset_index(drop=True)
            st.dataframe(rank_df.style.format({"å¹³å‡å¹´å¢žçŽ‡": "{:.2f}%"}), use_container_width=True)
        else:
            st.info("åŽŸå§‹æª”æœªåŒ…å«ã€Žå¹³å‡å¹´å¢žçŽ‡ã€æ¬„ä½")
    except Exception as e:
        st.warning(f"æŽ’è¡Œæ¦œç”Ÿæˆå¤±æ•—ï¼š{e}")

# =========================
# 9) è¿‘ä¸‰å€‹æœˆå¹´å¢žçŽ‡é€£çºŒæˆé•·
# =========================
with st.expander("ðŸ“ˆ è¿‘ä¸‰å€‹æœˆå¹´å¢žçŽ‡é€£çºŒæˆé•·", True):
    df_temp = df_yoy.dropna(subset=["æ—¥æœŸ"])
    unique_months = sorted(df_temp["æ—¥æœŸ"].unique())
    last3 = unique_months[-3:] if len(unique_months) >= 3 else []
    result = []
    if last3:
        df_l3 = df_temp[df_temp["æ—¥æœŸ"].isin(last3)]
        for sid in df_l3["ä»£è™Ÿ"].unique():
            d = df_l3[df_l3["ä»£è™Ÿ"] == sid].sort_values("æ—¥æœŸ")
            if len(d) == 3:
                y1,y2,y3 = d["å¹´å¢žçŽ‡"].values
                if pd.notna(y1) and pd.notna(y2) and pd.notna(y3) and y1 < y2 < y3:
                    result.append({
                        "ä»£è™Ÿ":sid, "åç¨±":d.iloc[0]["åç¨±"], "ç”¢æ¥­åˆ†é¡ž":d.iloc[0]["ç”¢æ¥­åˆ†é¡ž"],
                        "æœˆä»½1":pd.Timestamp(d.iloc[0]["æ—¥æœŸ"]).strftime("%Y-%m"), "å¹´å¢žçŽ‡1":round(float(y1),2),
                        "æœˆä»½2":pd.Timestamp(d.iloc[1]["æ—¥æœŸ"]).strftime("%Y-%m"), "å¹´å¢žçŽ‡2":round(float(y2),2),
                        "æœˆä»½3":pd.Timestamp(d.iloc[2]["æ—¥æœŸ"]).strftime("%Y-%m"), "å¹´å¢žçŽ‡3":round(float(y3),2)
                    })
    if result:
        df_res = pd.DataFrame(result)
        industries = ["å…¨éƒ¨é¡¯ç¤º"] + sorted(df_res["ç”¢æ¥­åˆ†é¡ž"].dropna().unique())
        sel_ind = st.selectbox("é¸æ“‡ç”¢æ¥­åˆ†é¡žï¼ˆç¯©é¸ï¼‰", industries, index=0)
        if sel_ind != "å…¨éƒ¨é¡¯ç¤º":
            df_res = df_res[df_res["ç”¢æ¥­åˆ†é¡ž"] == sel_ind]
        st.dataframe(df_res, use_container_width=True)
    else:
        st.info("ç›®å‰æ²’æœ‰è‚¡ç¥¨ç¬¦åˆã€Žè¿‘ä¸‰å€‹æœˆé€£çºŒæˆé•·ã€æ¢ä»¶ã€‚")

# =========================
# å°¾è¨»
# =========================
st.caption("å°æé†’ï¼šå¹´å¢žçŽ‡ç‚ºã€Žæœˆè³‡æ–™ã€ï¼Œè²¡å‹™æ¯”çŽ‡ç‚ºã€Žå­£è³‡æ–™ã€ã€‚è³‡æ–™ä¾†æºï¼šä½ æä¾›çš„ Google Drive CSVã€‚")
